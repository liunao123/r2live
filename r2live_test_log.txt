r2live发现的问题



1、在initialStructure过程中，首先用到的structure from motion（SFM），
   利用相邻帧上的特征点，来恢复出相机运动。
   只要特征点不是很少， SFM过程基本可以顺利完成。
   


2、图像恢复出的尺度因子经常是 负 的，
   在 1 描述的过程中，如果 SFM 成功，则会进行visualInitialAlign过程；
   此时，先通过VisualIMUAlignment来计算 IMU 的gyroscope bias，然后进行LinearAlignment过程，
   把相机的所有位置，重力加速度g，单目图像的尺度s；放到一起进行求解。
   一旦所估计出的重力加速度和IMU测量的差距过大，或者尺度因子为 负值 。此时 visualInitialAlign 过程失败，。
   就会出现 “Misalign of visual structure with IMU”的错误。
   
   目前分析来看，到此，起码图像的处理已经完成，但是 与 IMU 的测量有冲突，导致失败。


3、指定的外参旋转矩阵会被转成四元数，然后归一化。
   不同的旋转矩阵会对应一个位姿。
   当使用VINS在线估计出来的外参（绕3个轴的旋转角度）（176.517  -175.92  -179.874）比
                                    单独的标定得到的（171.864  -93.7768 -82.1446） 旋转看起来要符合实际情况。
   但是很明显，二者的方向是不一样的。
   测试发现：
   且 单独标定的外参 所指定的相机方向 和实际方向不一致，但 VINS在线估计出的相机方向 是 符合预期的。
   
   如果在进行建图时，采用固定不变的外参，则程序会有 “ 旋转矩阵不正交的 错误”， 然后挂掉。


4、最容易出现的错误：
Misalign of visual structure with IMU 《VisualIMUAlignment对齐有问题：estimator.cpp 408 有问题》
big IMU acc bias estimation
 github 上 作者的回复：
 Hi, firstly I suggest you to check your IMU stream, e.g. whether the IMU reading has a large bias.
 You can do integration and double-integration on IMU readings, the trajectory should be normal for seconds.
 把相邻的两个IMU数据取均值，这样频率降为原来的 一半，效果看起来区别不大。
 big IMU acc bias estimation 则是初始化的时候，得到的


5、目前来看，改变imu的噪声水平，对实时位姿的估计影响较大。
   目前利用imu_ultiz 估计出来的IMU噪声，如果将其扩大数倍（*2， *3 ， *5）
   扩大 ，可以减小reboot的频率, 但是点云的偏移部分会被放大，位姿会不稳定，重影会出现。
   当降低IMU的噪声水平时，地图的偏移会减小很多。


6、在建图过程中估计出的状态量（位姿，速度，零偏，重力加速度），会被进行 check ，
   测试发现 全局变量 g_lio_state 会出现速度过大的情况，
   
   在某一时刻的状态，其速度大于 10 时，系统旋转的估计有问题，给出提示，此时建图过程会跑偏。
   
   有2个位置会对其进行check， 并且大部分 时候的错误（估计出的速度过大），
   
   都是在 IMU_Processing.cpp 的imu_preintegration 函数中。
   当偏移发生时，并且这个速度 会 逐步增大很多。



7、硬件的硬同步问题，数据源之间的时间同步很重要，
目前来看，测试更改了图像的时间戳，缓存数量使得最新的图像可以及时发出去，明显减小图像的延迟。
但是图像与IMU的实际延迟依然不可得，目前让其在线估计该时间延迟，量级在0.001s级别。

   参数，可以调整一下
   #unsynchronization parameters
   estimate_td: 1                      # online estimate time offset between camera and imu
   td: 0.003--0.007                           # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)。


8、VIO部分单独测试，也是可以运行的。并且回环也可以检测到
   运行的稳定性和数据有关，
   在r2live容易报错的地方，VIO原来的代码是没有的。如：IMU_Processing.cpp； estimator_optimization.cpp;
   
   
9、建图的分辨率，
0.1m 很容易漂移
0.4m 默认的参数


参数保持与demo一致。

按以下思路进行测试：
1、IMU数据单独拿出来，看一下是否正常（用另一个IMU作为参考）；
2、重力加速度的量级，是否正常（正常端着走）；
3、IMU数据要对应到视觉上；


文件夹里的r2live-master测试版本：


20220810
1、目前的参数，楼下大圈和小圈的数据，vins都可以运行，但是尺度估计的不对，绕楼下几圈，轨迹会越来越小。
2，官方训练的数据集，今天测试下来对楼下室外环境基本检测不到回环。但是回环检测的节点却可以输出位姿，更新频率数秒一次，很低。并且与状态估计节点之间的topic里一直没有数据交互。

20220811
1、VINS的回环检测正常，将pose_graph的回环检测已经加入到R2live中，并且二者的数据交互正常；
2、位姿目前仅仅pose_graph可以通过检测到的回环进行纠正，r2live的轨迹还是偏移，然后点云地图更是如此；
3、回环检测使用的词袋文件（brief_k10L6.bin）是通用的。
4、启动pose_graph所需要的4个参数，目前使用：0 0 2 0.1，感觉良好。


20220812
1、estimator_node.cpp 第741行的 状态更新暂时注释掉了
2、


20220816
1、回环现在把优化的位姿保存下来，然后通过另外的程序结合 点云 的时间戳 进行插值
2、目前对 高度方向进行的 插值优化，感觉良好，但是水平方向上的偏移依然无法得到解决。

3、把fast_lio里面的位姿和点云也保存下来，然后只优化这个位姿的 Z 值，实现上述1和2。
4、common_lib.h里面关于 Lidar_offset_to_IMU 变量，需要注意。而且代码里面与官网提供的不一样。

20220829
测试发现 image 与 IMU的时间差，影响较大。应该先通过在线估计的形式，得到一个较好的 初始值。
然后将该初始值 再让其 在线估计，直到该数据稳定。

#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu
td: -0.02                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

2022年8月手持平台测试情况：
1、目前以步行的速度录制的数据，轨迹长度1800m，持续25分钟，建图可以稳定进行。回到起点位置附近，LIO部分输出的原始点云高度方向偏差约0.5m。水平偏移约1.6m。建图的稳定性、精度比之前都有改善。
2、建图参数 image 与 IMU的时间差，影响较大。目前先通过在线估计的形式，得到一个较好的 初始值（目前我们的是：-0.01s），然后以该值再进行建图，系统稳定性有所提高。
3、视觉回环部分可以正常工作，但是其回环结果没有与建图程序联系起来，无法直接利用回环结果去优化点云地图。测试利用插值的方式去单独优化每帧点云对应的位姿，得到的点云地图依然存在水平方向上的偏移，且位姿的方向不对，导致点云的细节很模糊。
4、基于GTSAM的回环检测目前正常进行，得到的结果较之前有所改善，但是由于回环目前采用关键帧逐一遍历的方式进行，所以搜索效率较低，很耗时。采用将建图开始时和结束的一段数据，跳过中间的数据，进行优化。
   当检测到回环后，GTSAM利用GICP得到的位姿变换，可以将点云在高度、水平方向的偏移纠正回来，虽然点云地图远处的细节有点模糊，但近处的细节保留的较好。
5、为了加快回环的速度，目前将以视觉检测到的回环为准，保留该回环发生的时间，然后点云的回环将以该时间为准，不再进行暴力遍历的方式进行。具体检测的效率如何仍在测试。
6、计划再采集更长的数据，测试建图效果

2022年9月5-9号工作汇总：
1、测试对于livox点云的特征点提取代码，目前利用loam_livox里面的代码可以将平面点提取出来。而r2live里面点和面都可以提取出来，但是后续的r2live后续只用到了平面点。
2、本周又录了2个包，一个是绕园区外侧一周，可以稳定建图，利用GTSAM优化后的点云效果良好。另一个绕园区主干道，用时40分钟，长度3000m左右。建图稳定，而GTSAM的优化效果尚不理想，仍在优化。
   目前2个思路，其一：调整回环检测的条件，增加检测到的回环数，其二：利用上述提取的平面点，来尝试提高GICP的匹配精度。

2022年9月19-23号工作汇总：
1、测试不同参数对点云地图优化的影响，现在发现0.5m的关键帧阈值， 0.36的GICP阈值较为合适，过小的阈值会使得部分细节变得模糊，并且导致回环过少。
2、点云地图在轨迹交叉，但是没有回环的位置容易发生重影，其中部分位置通过手动加入回环可以将重影消除，其余轨迹交叉的位置是很难有回环的。
3、在部分轨迹重复的区域，依然不能如预期那样检测到回环，目前综合考虑，怀疑是某条轨迹上存在动态障碍物，这样点云的特征不再一致，导致匹配出问题，进而检测不到回环。
4、机械的同事将新的相机安装上，利用视觉组的电子标定板和程序，内参标定完成。特征提取偶尔还是会有蓝线出现，这是对特征点提取错误，后续测试对建图影响不大。
5、到楼下采集一点数据进行在线外参标定，在线外参标定基本正常，利用标定后的外参近建图也可以正常进行。

2022年9月26-30号工作汇总：
1、更换新的相机后，进行内外参的标定。其中外参以在线的方式完成。目前标定完成，可以正常使用。
2、测试重复轨迹较多的情况下，GTSAM的优化情况。在每栋楼大概绕了1.5圈的方式进行建图，这样每栋楼都会有0.5圈的长度上有机会检测到回环。
3、在重复轨迹较多的数据上，发现：较密集（0.3--0.5m）的关键帧并不能得到理想的效果，而稍微稀疏（0.75m）一点的关键帧效果会更好一些。但是此时的点云数量会下降，不知对后续定位的影响有多大。
4、以上述方式所得到的地图，目前在效果比之前有所改善，目前测试了20分钟约2000m的建图轨迹，优化后的地图基本没有重影。
5、开始基于上述的地图，测试ndt_localizer的定位效果，以建图的bag来模拟定位过程，发现定位不稳定，每次给定初始位置后，定位也会在不久后丢失。
6、针对目前定位的问题，后续一方面学习调参，另一方面调研点云+视觉的定位方法。

2022年10月8-14号工作汇总：
1、测试路线：每栋楼绕了大概1.5圈的数据集，此时检测回环的数量会增加很多，此时每栋楼局部的约束很多，在开始和结束的位置上再检测到一些回环，基本可以得到效果不错的地图。
2、在上述路线中发现：某些相似的环境中，GICP给出的回环有可能是错误的，此时匹配得分很低，但是是约束不对，导致优化出现问题，这是相似环境导致的。
3、测试先大圈后小圈的路线：发现在重复路线较多的位置上，回环检测没有问题，该位置的地图也没有问题，但是重复路线较少（如只重复了一栋楼的宽度）的位置依然无法稳定的检测出回环，也就无法优化该位置的地图。
4、调研测试适用于livox的激光定位算法：之前的lidar_localizatuon之类的算法都是针对机械激光雷达设计的。livox_localization和fast_lio_localization是适用livox的。初步测试发现：
   前者需要指定一个较为精确的初始值，测试发现在rviz里指定一个大致的位置，程序很难重定位成功，后者则需要生成关键帧的scan context在定位时使用，目前在尝试生成我们自己的scan context。
5、测试Livox-Mapping来生成点云对应的scan context，以及利用scancontext的开源代码测试生成定位用的文件。


2022年10月17-21号工作汇总：
手持建图工程化 60%
1、地图优化与建图整合到一起，现在二者可以同时进行，不过目前运行的很慢，
   主要是后期内存(pose_graph)占用很高。：// TODO 内存泄漏？
   小一点的数据上测试，没有问题。较长的路线正在测试......
   service call /end_gtsam {}

手持定位 20%
视觉激光融合：
2、2D-3D-pose-tracking（https://github.com/Zumbalamambo/2D-3D-pose-tracking）依赖CUDA，
   在测试没有GPU的情况下咋样。
3、3D line detection部分代码运行成功；C:\Users\xf\Desktop\3d.png
纯激光：
4、livox_localization之前初始化较慢，甚至长时间不能重定位到正确的位置上，
   猜测是目前利用keyframe生成的scan context密度小。(0.75m)。计划使用较密的scan context测试。

定位：纯激光 + 短距离的里程计(长走廊环境)
列检机器人，坑道环境（办公室走廊-定位功能做完之后）
问题的复现：

2022年10月24-28号工作汇总：
1、利用valgrind工具排查，pose_graph有无内存泄露出现.不过很小，几kb的量级。
   在测试其关键帧new出来后，手动delete，发现运行期间程序会挂掉。
2、先大圈再小圈的建图路线，测试发现，在某些重复轨迹上，视觉也没有检测到回环，就很奇怪。
3、livox_localization更改一些参数，以及加大scan contextd密度后（0.3m/个），可以进行重定位。
   3.1 开始阶段重定位一旦收敛到准确的位置上，后面可以一直定位下去。建图和定位用同一段bag文件。发现定位结果在Z轴方向上存在一定的偏差。
   3.2 当建图与定位不是同一个bag文件时，地图的动态变化部分，会使得定位有较大波动。
   3.3 目前发现在某些位置上（视野开阔的地方），在5s左右可以重定位完成，而在某些位置上，会一直无法重定位成功。
5、尝试给livox_localization添加一个手动重定位的功能，现在其可以收到在rviz里给出的位置，但重定位结果有问题，仍需测试。
4、2D-3D-pose-tracking 里用到的 AFM ，需要cuda的库，暂时无法进行测试。
   发现了一个非ros的视觉点云定位算法：https://github.com/hyye/dsl，也需要cuda。

视觉组的电脑
2022年11月01-11号，手持导航平台工作汇总：
1、定位的初始位姿，通过手动运行程序来指定。
   初始位姿是通过：livox_localization中的scan context来获取的。然后通过“/initialpose”发布出去。完成

2、基于点云地图的定位，尝试以r2live的视觉激光融合里程计来输出。
   基于1：手动指定一个精确的初始位姿，将r2live前端里程计的起点转换到初始位姿上。从上述位姿开始建图，同时也得到了基于地图的位姿。完成
   
   以上述方式得到的，存在2个问题：1：过分依赖初始值；2：r2live的原始里程计的精度是什么样就什么样，无法得到改善。

3、ssl_slam2（intel的固态激光雷达）的角点+ 面点 正在测试。
   目前从地图中分离 角点 和 面点 有问题，感觉提取之后就不再是点云了。

后期工作：
1、下周调研确定：全局定位算法（scan context or icp or 粒子滤波 ...... ）确定用什么
2、r2live前端里程计 测试稳定下来，短时间内的里程计要稳定。
//TODO: 二者结合


2022年11月14-18号
1、点云相似度的库：https://github.com/Dongxu05/CSSC
   在没有指定初始值的情况下比GICP快很多

需要GPU
2、基于分割的定位算法：https://github.com/ethz-asl/segmap
3、深度学习定位算法： 
             https://github.com/PRBonn/overlap_localization
             https://github.com/PRBonn/range-mcl
             https://github.com/JuanDuGit/DH3D

纯激光的定位定位算法：
4、全局重定位的算法 : https://github.com/koide3/hdl_global_localization
                    https://github.com/koide3/hdl_localization
   在机械雷达下，可以实现全局定位功能，有图
   livox雷达，全局定位不行，给定初始位姿，收敛的很快，计算速度也可以跟上
   
   
5、https://github.com/carlosmccosta/dynamic_robot_localization
   利用 livox 激光数据进行测试，发现：
   1：tf tree是完整的，但是定位位姿没有输出
   2：所指定的初始位姿，没有起作用，会强制从原点可以定位。
   3：需要一个里程计数据，现在是通过r2live给出的

6、r2live的简化成前端里程计，现在单独形成一个节点，输出位姿，配合其他节点一起使用。
   1；r2live_locate 前端
   2: publish_initial_pose.py 发送初始值
   3：reprject_r2live_path 根据初始位姿，将r2live的位姿变换过去。

后续计划：
   1、实验室建图：原来的定位方式，对比现在的定位咋样，
   室外，合肥场地试一下。
      
   手持建图 + 机器人定位
   
   
   室外：手持建图 + 手持定位可以用
   
2022年11月21-25号
1、 https://github.com/koide3/hdl_global_localization
   全局定位算法，提供三种实现：
   1、BBS, 
   2、FPFH_RANSAC
   3、FPFH_TEASER
   第一个，官方的机械激光可以完成自动重定位工作，目前测试发现不适用于livox雷达点云。
   另外2个，简单测试，发现其接口无法在返回重定位的结果。
   
2、室内建图测试：
   1、走廊环境绕一圈，存在部分漂移。
   2、单纯的办公室环境，不用优化，也可以得到较好的地图。

3、室外定位测试：
   结合IMU数据，https://github.com/koide3/hdl_localization 可以完成大部分位置的定位工作。
   在用10月份的地图，结合8月份的数据，进行测试 发现：
   有以下位置会定位失败
   1、快速的旋转；
   2、在树比较多的位置；
   3、地图点云较少

4、室内定位测试：
   1、静止状态下，hdl的精度6cm左右。
   2、部分场景，单纯的激光，没有iMU会导致定位失效

   <!-- 全局定位先放一下 -->
   1、r2live前端里程计，融入hdl的odom predict里面去
   2、看一下hdl里面的tf在哪个地方发布的
  //TODO  3、室内外的 重复定位精度
   4、手持导航平台2.0的标定工作

2022年11月28号-12月2号
r2live
整体建图可以正常使用，无明显问题，简化版本的里程计也可以稳定输出
1、室内，将WINDOW_SIZE从7改为9/11/15，稳定性好很多。但是初始化global SFM的时间越长。
2、建图中的视觉失败，利用OpenCV里面的5点法，求解相邻帧的位姿很容易失败，
   导致错误。其实还是特征不够


hdl定位 
3、仅使用点云与imu, 大部分位置都是正常的， --- 在走廊拐弯的地方，点云会全部打在对面墙上，导致定位发生漂移。
4、融合r2live的里程计，用bag测试，
   4.1 里程计长时间运行后，数据处理跟不上，导致tf的时间戳有延迟。现在在测试修改数据的时间戳 
   4.2 r2live的里程计，其在高度方向上长时间的累计漂移仍存在，hdl给出的定位没有明显的高度问题。

5、机器人测试室内手持平台所建地图，办公室内可正常定位，测试精度在4cm以内

后续计划：
6、// 修改数据的时间戳，保证tf时间戳可用，用bag包测试。
7、融合r2live的里程计，进行实时定位测试，室内 + 室外。
8、手持平台2.0，标定工作。

  数据 丢 一些，保证实时性。

2022年12月5号-12月9号

手持平台配置： i7 8550U 1.8Ghz * 8

1、数据时间戳的问题，是 use_sim_time 要和 --clock 配合使用。、
2、定位实时性与2个方面有关：
   2.1 里程计的稳定性
   2.2 hdl的计算效率，其中初始化阶段较慢，如果指定了一个正确的初始位姿，定位会稳定很多。
3、为了保证里程计的稳定输出，对原始数据的缓存进行了限制，点云和视觉均保留最近 1s 内的数据。
4、在手持平台上，点云以 8hz 的输入，在 速度为 1m/s 左右时，单纯的里程计也可以稳定输出。一旦开启hdl，数据将会不能实时处理
5、手持平台，平面点（/laser_cloud_flat）作为 r2live 和 hdl 的共同输入，
   hdl无法获取 点云所在时间上的 里程计信息，二者的延迟在 0.4s 左右（里程计计算的时间+数据传输时间）
   此时，hdl的定位输出 在 3hz 左右。 -------- 1小时34分

后续计划：
7、在i7电脑上加内存条，再测试 融合里程计 后的hdl定位效果。
8、继续优化 在手持平台上 的 定位实时性 （）速度  0.3 - 0.5m/s

6、手持平台2.0，标定工作。

10、在手持平台上，测试粒子滤波定位的效果。


9、把地图的地面找出来，旋转一下，把地图放平。


2022年12月12号-12月16号

目前测试的配置： i7 8700  16G  3.2Ghz * 12

1、速度在0.3--0.5m/s左右的数据，里程计的稳定性相对差一些，但是更改定位的逻辑后，对定位基本无影响。
2、速度在0.3--0.5m/s左右的数据 测试定位：
   整个园区的大地图（分辨率0.3m,点数:2197306），10hz的点云输入，odom输出在8hz左右，
   正常定位时的延迟在 0.15s 左右。
   
   半个园区的小地图（分辨率0.3m,点数:1050303），10hz的点云输入，可以有9 hz的odom输出。延迟在 0.1s 左右 

3、更改hdl的定位逻辑，在里程计可用时，正常融合里程计，当里程计不稳定时，暂时不适用里程计。2个逻辑改动;
   其一：重启里程计节点，此时重启将会5s左右完成，然后里程计又可以正常输出，
   其二：在里程计重启这段时间，hdl仅仅依靠点云与IMU数据，基本也可以正常定位。

4、根据hdl实时定位的位置，将点云投影到地图中，以点云分辨率的大小为搜索范围（/max_correspondence_dist 参数），
   计算点云的匹配度，测试发现，在正常定位的时候，匹配度稳定在0.9左右，定位丢失时，该值会快速减小。

5、旋转地图：把地图中的地面旋转到 大致水平的位置上。此时，地面点的 Z 值基本一致，依靠pcl中平面提取完成。

褚哥测试结果：
6、手持平台上粒子滤波定位算法测试：
   在大地图上，速度1.5m/s , 延迟很小，可以实时处理
   定位稳定性 依赖r2live提供的里程计，当里程计不稳定时，定位会丢失
   地图分辨率0.3,点数:200万左右 ，对于非地图相同bag有时候会定位不稳定


下周计划：

7、手持平台2.0，标定工作。

8、尝试将手持平台放在机器人平台上 采集数据，测试 在基本匀速运动时，以及 静止状态下的 定位情况

9、手持平台粒子滤波  再优化，r2live里程计不能用，使用其他里程计

    hdl定位的匹配度低于（某一个阈值，如：0.1） 时，，位姿暂时使用里程计推算，输出

10、手持平台在楼下实时测试定位 

11、定位视频：
    室内 + 室外
	地图彩色 + 点云蓝色
	位姿估计置信度 尝试加到rviz里面显示 (1)
	
	静止状态下的精度
	重复定位精度
	最高 常规定位精度

2022年12月19号-12月23号
1、制作hdl定位的视频，室内和室外，在视频上添加位姿与置信度等内容，显示出来。
2、用小车去采集静止状态下的数据，测试HDL在静止状态下的定位精度。
3、准备年度汇报的PPT，进行年度工作汇报。
4、测试hdl在静止状态下的定位精度，目前初步测试发现其室内定位精度在0.03m，室外定位精度0.05m，高度方向上的波动在0.02m左右。
5、测试hdl失败时，用里程计补偿的定位逻辑。目前因为时间戳的问题，里程计补偿效果不好。

2022年12月26号-12月30号
1、HDL定位失败时，利用里程计内插出相邻时刻的位姿，在之前定位成功的位姿基础上，临时补偿一下，
   目前 利用 TF的lookupTransform功能，在里程计正常的时候，统计发现：有30%左右的概率补偿成功。

2、尝试利用原始里程计里的速度信息来补偿定位失败时的位置，测试发现效果没有明显变化，
   里程计不输出的本质问题还是没有解决，长时间没有里程计的时候，该方式依然不可行。

3、在静止测试中，30s左右的静止状态下，里程计是肯定会重启的，并且VIO需要一定的运动才能正常输出里程计，导致里程计缺失的时间好像变长了。

4、在小车上近乎匀速的运动过程中，除个别情况（某个轮子突然卡主，出现突然的转弯），里程计输出的稳定性有所改善。



2023年1月3号-1月6号
1、v2.0相机标定，以原始分辨率（1280*1024）和降分辨率（640*512）后，都标定了一次。

2、IMU的噪声水平 进行估计。

3、v2.0相机与imu的外参标定，目前得到的外参用来建图效果不稳定。

   主要是视觉方面：1、在室内进入走廊环境中，容易重启，2、拐弯后，视觉的稳定变差。
   3、建图存在明显的高度方向累计误差

4、建图过程出现一个之前没有的警告， IMU、点云、视觉的时间差问题。
   
下周计划：
1、第四个问题的时间差 分析 一下 。看一下VIO稳定性是否与这个有关。
2、外参继续优化。之前有一个外参得到了一个较好的结果。
3、继续尝试 室外 建图 


2023年1月9号-1月13号
1、图像的分辨率 ：原始分辨率（1280*1024）和降分辨率（640*512），目前来看对 建图 影响不大
   在r3live中，可以对原始的 图像 进行降采样 来加快速度。
2、发现IMU数据读取的不够均匀。偶尔相邻两个数据向外的发布的时间间隔过大，在0.02s的量级。出现的频率在3-5min就有一次。
3、目前imu的输出收到其他程序的影响。建图程序启动后，第一个问题出现的频率汇会增加
4、外参继续优化，使用目前的外参。手持平台2.0上采集的数据，在r3live和fast_livo上可以正常运行，r2live则很不稳定，无法建图。
   其中：手持平台1.0的数据目前 在fast_livo上也可以运行，虽然其里程计输出频率高，但是建图效果看上去 没有r2live精细。
5、可能的问题：
   1、传感器之间的外参标定问题：不同的项目需要标定的传感器不同， r2live需要的是 camera2imu。r3live和fast_livo需要的是 lidar2camera.
      手持平台2.0上，lidar与imu的位置现在认为 二者是没有相对旋转的，实际上肯定不是。
   2、IMU的时间稳定性，<r3live是需要lidar和imu直接的时间差的，目前当成 0 来处理>
   3、传感器之间的时间硬同步。一直没做

下周工作：
1、继续标定一下两个版本的  lidar和camera的外参。
2、手持平台2.0上整个园区的建图测试 fast_livo 和 r3live
% 3、fast_livo里程计尝试融合到 hdl 里面

2023年1月16号-1月18号
1、之前速腾的驱动没有将点云信息转成与velody_points完全一致，缺少了time与ring字段，导致部分项目适用于velody 雷达的配置参数无法直接使用。
   更新速腾雷达的驱动，结合https://github.com/HViktorTsoi/rs_to_velodyne项目将其点云缺少的信息补充上，保证与velody的格式一致。

2、利用https://github.com/hku-mars/LiDAR_IMU_Init项目对v2的雷达与imu外参进行标定。现在的标定过程稳定很多，得到lidar与imu直接的外参与时间延迟。MP4

3、利用在楼下大厅标定的雷达与imu外参、室内标定的lidar与camera外参， 三者的时间同步暂时不考虑。 室内外目前可以完成建图，
   效果比之前假定lidar与imu平行时，要好一些。pic

4、进行标定时，要静止几秒再开始，然后直到提示 在线 优化完成。。而 FAST_LIVO ，不能从静止开始。FAST_LIO可以

5、雷达与相机的外参标定，现在感觉受限于 16线 点云 比较稀疏，标定效果感觉还有待提升。

下周计划：
1、lidar2imu外参优化
2、lidar2camera外参优化
3、测试建图中 静止一段时间后，继续建图的稳定性
4、室外大范围的建图测试。

2023年1月28号-2月3号
1、利用建图算法得到较为稠密的场景点云 ，再次对雷达与相机 进行外参标定。目前两个版本 都有了可用的外参。

2、查找时间硬同步的资料，暂时没有做时间硬同步。
   但是尝试做了一下软同步：模仿 fast_livo 官方的数据，将雷达与相机的数据时间戳保持一致，频率一致。测试发现效果还不如原来。轨迹的扭曲现象更容易出现。

3、fast_livo里面在讲点云投影到全局坐标系时，没有考虑到雷达与imu直接的相对旋转，现在把该参数添加进去。

4、在v2的数据上测试 fast_livo 。目前在 楼下 ， 约 600 m的轨迹上，可以正常运行。 可以从静止状态下开始，直接的建图效果没有明显重影问题。

5、在v1的数据上测试 fast_livo 。绕楼下一圈，无明显重影。去年10月份的数据。绕整个园区一周，其高度方向存在漂移。
   从静止状态下开始，漂移很大。但是手持状态下，尽量保持不动再开始，就没有问题。

下周计划：
1、 v2  在整个园区的建图测试
2、 v1  数据（整个园区范围）在fast_livo上测试
3、 v2  上建图加上回环优化功能