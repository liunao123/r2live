%YAML:1.0

imu_topic: "/livox/imu"
image_topic: "/camera/image_color"
output_path: "/home/map/"

#camera calibration 
model_type: PINHOLE
camera_name: camera

image_width: 640
image_height: 512
#image_width: 1280
#image_height: 1024

distortion_parameters:
    k1: -5.19669237e-02  #-0.0538
    k2: 1.03347881e-02 #0.1415
    p1: -4.1708394e-04 #-0.000407
    p2: -1.35346319e-04 #-0.002039
    k3: 1.69413025e-01  #-0.144126
   
projection_parameters:
   # fx: 872.29034854 #875.1884
   # fy: 872.70355403 #870.0817
   # cx: 642.48042151 #638.3153
   # cy: 511.24930372 #495.8590

    fx: 436.15 #875.1884
    fy: 436.35 #870.0817
    cx: 321.24 #638.3153
    cy: 255.12 #495.8590

# Extrinsic parameter between IMU and Camera.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.
estimate_extrinsic: 0    # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 2  Don't know anything about extrinsic parameters. You don't need to give R,T. We will try to calibrate it. Do some rotation movement at beginning.                        
#If you choose 0 or 1, you should write down the following matrix.
#Rotation from camera frame to imu frame, imu^R_cam
extrinsicRotation: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
#   data: [0.0,  -1,  0,
#          0.0, 0,  1.0, 
#          1.0, 0,  0]

   #data: [-0.032766,  -0.999311,  -0.0183451,
   #       -0.0159459, 0.0188672,  -0.999695, 
   #       0.999352, -0.0319742,  -0.0165439]


#<deg>  x: -89.3478232, y: 1.1291202, z: -93.2628864
#<xyzw> -0.4776738, 0.5158853, -0.5121674, 0.4933301
# get by vins
   data: [-0.0569061 , 0.0124856 ,  0.998301,
          -0.998185 , 0.0190247, -0.0571374,
          -0.0197058,  -0.999741 , 0.0113804]

   #data: [0.00113207,  -0.0158688,  0.999873,
   #      -0.9999999, -0.000486594,  0.00113994, 
    #      -0.00113994, -0.999874,  -0.0158682]

   #data: [0.00113207, -0.9999999, 0.000504622,
   #      -0.0158688, -0.000486594, -0.999874,
   #      0.999873, -0.00113994, -0.0158682]

#Translation from camera frame to imu frame, imu^T_cam
extrinsicTranslation: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   #data: [0.091764, 0.00808499, 0.051303]
   #data: [0.05, -0.06, -0.01]
   #data: [0.141631,-0.012601,-0.0358588]
   data: [ 5.9901766414594604e-02, -5.9949797880541972e-02, -3.3726108959814156e-02 ]

   
#feature traker paprameters
max_cnt: 150           # max feature number in feature tracking
min_dist: 30            # min distance between two features 
freq: 5                 # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image 
F_threshold: 1.0 #1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
equalize: 1             # if image is too dark or light, trun on equalize to find enough features
fisheye: 0              # if using fisheye, trun on it. A circle mask will be loaded to remove edge noisy points

#optimization parameters
max_solver_time: 0.04  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8  # max solver itrations, to guarantee real time
keyframe_parallax: 10  # keyframe selection threshold (pixel)

#imu parameters       The more accurate parameters you provide, the better performance
acc_n: 4.0362832364835711e-02 #2.0558110444478399e-02          # accelerometer measurement noise standard deviation. #0.2
gyr_n: 4.9356634372495680e-03 #2.8851885453467061e-03         # gyroscope measurement noise standard deviation.     #0.05
acc_w: 6.8237464228441125e-04 #3.8550325711409205e-04         # accelerometer bias random work noise standard deviation.  #0.02
gyr_w: 6.3184059394302349e-05 #3.0639709624135159e-05      # gyroscope bias random work noise standard deviation.     #4.0e-5
g_norm: 9.79484       # gravity magnitude



#loop closure parameters
loop_closure: 1                    # start loop closure
load_previous_pose_graph: 0        # load and reuse previous pose graph; load from 'pose_graph_save_path'
fast_relocalization: 1             # useful in real-time and large project
pose_graph_save_path: "/home/map/pose_graph_result/" # save and load path

#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu
td: -0.02                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#rolling shutter parameters
rolling_shutter: 0                  # 0: global shutter camera, 1: rolling shutter camera
rolling_shutter_tr: 0               # unit: s. rolling shutter read out time per frame (from data sheet). 

#visualization parameters
save_image: 1                   # save image in pose graph for visualization prupose; you can close this function by setting 0 

visualize_imu_forward: 0        # output imu forward propogation to achieve low latency and high frequence results
visualize_camera_size: 0.4      # size of camera marker in RVIZ



